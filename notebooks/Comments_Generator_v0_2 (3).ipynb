{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. INSTALL REQUIRED PACKAGES\n",
        "!pip install -q transformers torch accelerate\n",
        "!pip install -q pandas numpy tqdm\n",
        "!pip install -q langdetect textblob\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Packages installed!\")\n",
        "\n",
        "# Clear GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"üîÑ GPU memory cleared\")"
      ],
      "metadata": {
        "id": "HMdtOAEQjDZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. WORKING NATURAL GENERATOR\n",
        "class WorkingTunisiaGenerator:\n",
        "    \"\"\"Simple but reliable natural comment generator\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"üîß Using device: {self.device}\")\n",
        "\n",
        "        # Use GPT-2 which is more reliable than DialoGPT\n",
        "        self.model_name = \"gpt2\"\n",
        "\n",
        "        # Load model and tokenizer\n",
        "        self._load_model()\n",
        "\n",
        "        # Tunisian places\n",
        "        self.places = [\n",
        "            {\n",
        "                \"name\": \"Sidi Bou Said\",\n",
        "                \"type\": \"coastal village\",\n",
        "                \"features\": [\"blue and white architecture\", \"cliffside views\",\n",
        "                            \"Caf√© des Nattes\", \"art galleries\", \"sea breeze\"],\n",
        "                \"activities\": [\"sipping mint tea\", \"watching sunsets\",\n",
        "                              \"taking photographs\", \"walking narrow streets\"]\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"Tunis Medina\",\n",
        "                \"type\": \"historic city\",\n",
        "                \"features\": [\"ancient souks\", \"Zitouna Mosque\", \"traditional crafts\",\n",
        "                            \"narrow alleyways\", \"historic architecture\"],\n",
        "                \"activities\": [\"shopping for souvenirs\", \"exploring mosques\",\n",
        "                              \"trying street food\", \"people watching\"]\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"Hammamet\",\n",
        "                \"type\": \"beach resort\",\n",
        "                \"features\": [\"sandy beaches\", \"historic fortress\", \"orange groves\",\n",
        "                            \"luxury resorts\", \"medina walls\"],\n",
        "                \"activities\": [\"sunbathing\", \"water sports\", \"spa treatments\",\n",
        "                              \"exploring the old town\"]\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"Djerba\",\n",
        "                \"type\": \"island\",\n",
        "                \"features\": [\"white sandy beaches\", \"traditional architecture\",\n",
        "                            \"El Ghriba synagogue\", \"palm trees\", \"clear waters\"],\n",
        "                \"activities\": [\"beach relaxation\", \"cultural visits\", \"seafood dining\",\n",
        "                              \"shopping for handicrafts\"]\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"Carthage\",\n",
        "                \"type\": \"archaeological site\",\n",
        "                \"features\": [\"Roman ruins\", \"ancient amphitheater\", \"museum\",\n",
        "                            \"coastal views\", \"historic artifacts\"],\n",
        "                \"activities\": [\"exploring history\", \"museum visits\", \"guided tours\",\n",
        "                              \"learning about ancient civilizations\"]\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Statistics\n",
        "        self.stats = {\n",
        "            'generated': 0,\n",
        "            'failed': 0,\n",
        "            'en': 0,\n",
        "            'fr': 0\n",
        "        }\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load GPT-2 model with proper settings\"\"\"\n",
        "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "        print(\"üì• Loading GPT-2 model...\")\n",
        "\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(self.model_name)\n",
        "\n",
        "            # CRITICAL: Set padding token\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            # Move to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                self.model = self.model.to(self.device)\n",
        "                print(f\"‚úÖ Model loaded on GPU\")\n",
        "            else:\n",
        "                print(f\"‚úÖ Model loaded on CPU\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading model: {e}\")\n",
        "            # Fallback to distilgpt2\n",
        "            print(\"üîÑ Falling back to distilgpt2\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            if torch.cuda.is_available():\n",
        "                self.model = self.model.to(self.device)\n",
        "\n",
        "    def create_simple_natural_prompt(self, place, sentiment, language):\n",
        "        \"\"\"Create simple, natural prompts that work\"\"\"\n",
        "\n",
        "        # User personas for natural feel\n",
        "        personas_en = [\n",
        "            \"a solo traveler from the UK\",\n",
        "            \"a couple on their honeymoon\",\n",
        "            \"a family with two children\",\n",
        "            \"a group of friends on vacation\",\n",
        "            \"a retired couple traveling\"\n",
        "        ]\n",
        "\n",
        "        personas_fr = [\n",
        "            \"une voyageuse seule de France\",\n",
        "            \"un couple en voyage de noces\",\n",
        "            \"une famille avec deux enfants\",\n",
        "            \"un groupe d'amis en vacances\",\n",
        "            \"un couple retrait√© qui voyage\"\n",
        "        ]\n",
        "\n",
        "        if language == 'fr':\n",
        "            persona = np.random.choice(personas_fr)\n",
        "\n",
        "            # Different prompt styles for different sentiments\n",
        "            if sentiment == 'positive':\n",
        "                starters = [\n",
        "                    f\"Je reviens d'un s√©jour √† {place['name']} et je voulais partager mon exp√©rience incroyable.\",\n",
        "                    f\"Mon voyage √† {place['name']} a √©t√© absolument merveilleux.\",\n",
        "                    f\"Je viens de passer quelques jours √† {place['name']} et c'√©tait fantastique.\"\n",
        "                ]\n",
        "            elif sentiment == 'negative':\n",
        "                starters = [\n",
        "                    f\"Je dois √™tre honn√™te sur mon exp√©rience √† {place['name']}.\",\n",
        "                    f\"Mon s√©jour √† {place['name']} n'a pas √©t√© √† la hauteur de mes attentes.\",\n",
        "                    f\"Je reviens de {place['name']} avec des sentiments mitig√©s.\"\n",
        "                ]\n",
        "            else:  # neutral\n",
        "                starters = [\n",
        "                    f\"Je viens de visiter {place['name']} et voici mon exp√©rience.\",\n",
        "                    f\"Mon s√©jour √† {place['name']} √©tait int√©ressant.\",\n",
        "                    f\"Je vais partager mon exp√©rience √† {place['name']}.\"\n",
        "                ]\n",
        "\n",
        "            starter = np.random.choice(starters)\n",
        "\n",
        "            # Natural continuation\n",
        "            prompt = f\"{starter} En tant que {persona}, \"\n",
        "            prompt += f\"j'ai vraiment appr√©ci√© {np.random.choice(place['features'])}. \"\n",
        "            prompt += f\"L'activit√© que j'ai pr√©f√©r√©e √©tait {np.random.choice(place['activities'])}. \"\n",
        "            prompt += \"Pour √™tre honn√™te, \"\n",
        "\n",
        "        else:  # English\n",
        "            persona = np.random.choice(personas_en)\n",
        "\n",
        "            if sentiment == 'positive':\n",
        "                starters = [\n",
        "                    f\"Just got back from {place['name']} and had to share my amazing experience.\",\n",
        "                    f\"My trip to {place['name']} was absolutely wonderful.\",\n",
        "                    f\"I just spent a few days at {place['name']} and it was fantastic.\"\n",
        "                ]\n",
        "            elif sentiment == 'negative':\n",
        "                starters = [\n",
        "                    f\"I need to be honest about my experience at {place['name']}.\",\n",
        "                    f\"My stay at {place['name']} didn't meet my expectations.\",\n",
        "                    f\"I'm back from {place['name']} with mixed feelings.\"\n",
        "                ]\n",
        "            else:  # neutral\n",
        "                starters = [\n",
        "                    f\"Just visited {place['name']} and here's my experience.\",\n",
        "                    f\"My stay at {place['name']} was interesting.\",\n",
        "                    f\"I want to share my experience at {place['name']}.\"\n",
        "                ]\n",
        "\n",
        "            starter = np.random.choice(starters)\n",
        "\n",
        "            # Natural continuation\n",
        "            prompt = f\"{starter} As {persona}, \"\n",
        "            prompt += f\"I really enjoyed {np.random.choice(place['features'])}. \"\n",
        "            prompt += f\"My favorite activity was {np.random.choice(place['activities'])}. \"\n",
        "            prompt += \"Honestly, \"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def generate_natural_text(self, prompt, language='en', max_length=100):\n",
        "        \"\"\"Generate natural text with proper error handling\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Tokenize with attention mask\n",
        "            inputs = self.tokenizer(\n",
        "                prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=50,\n",
        "                padding=True  # Add padding\n",
        "            )\n",
        "\n",
        "            # Create attention mask\n",
        "            attention_mask = inputs['attention_mask']\n",
        "\n",
        "            # Move to device\n",
        "            if torch.cuda.is_available():\n",
        "                inputs['input_ids'] = inputs['input_ids'].to(self.device)\n",
        "                attention_mask = attention_mask.to(self.device)\n",
        "\n",
        "            # Generate with safe parameters\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    input_ids=inputs['input_ids'],\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=max_length,\n",
        "                    min_new_tokens=30,\n",
        "                    temperature=0.8,  # Balanced temperature\n",
        "                    top_p=0.9,\n",
        "                    top_k=50,\n",
        "                    repetition_penalty=1.1,  # Lower to avoid repetition\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.pad_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    no_repeat_ngram_size=2,\n",
        "                    num_return_sequences=1,\n",
        "                    length_penalty=0.8  # Encourage natural length\n",
        "                )\n",
        "\n",
        "            # Decode\n",
        "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the new text (after prompt)\n",
        "            if prompt in generated_text:\n",
        "                generated_text = generated_text[len(prompt):].strip()\n",
        "\n",
        "            # Clean the text\n",
        "            generated_text = self._clean_natural_text(generated_text)\n",
        "\n",
        "            # Validate\n",
        "            if generated_text and len(generated_text.split()) >= 10:\n",
        "                return generated_text\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Generation error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _clean_natural_text(self, text):\n",
        "        \"\"\"Clean text to be natural\"\"\"\n",
        "\n",
        "        # Remove any meta-instructions\n",
        "        unwanted = [\n",
        "            \"In my review, I would say\", \"My TripAdvisor review would be\",\n",
        "            \"As a tourist, I would write\", \"Here is my honest review:\",\n",
        "            \"Dans mon avis, je dirais\", \"Mon avis sur TripAdvisor serait\",\n",
        "            \"En tant que touriste, j'√©crirais\", \"Voici mon avis honn√™te:\"\n",
        "        ]\n",
        "\n",
        "        for phrase in unwanted:\n",
        "            if phrase in text:\n",
        "                text = text.replace(phrase, \"\")\n",
        "\n",
        "        # Remove incomplete sentences at the end\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "        if len(sentences) > 1:\n",
        "            # Keep all but the last sentence if it seems incomplete\n",
        "            if not sentences[-1].endswith(('.', '!', '?')):\n",
        "                text = ' '.join(sentences[:-1])\n",
        "            else:\n",
        "                text = ' '.join(sentences)\n",
        "\n",
        "        # Clean whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Ensure it starts with capital letter\n",
        "        if text and len(text) > 1:\n",
        "            text = text[0].upper() + text[1:]\n",
        "\n",
        "        # Ensure it ends with punctuation\n",
        "        if text and text[-1] not in ['.', '!', '?']:\n",
        "            text = text.rstrip(',;:') + '.'\n",
        "\n",
        "        return text\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        \"\"\"Simple sentiment analysis\"\"\"\n",
        "        from textblob import TextBlob\n",
        "\n",
        "        try:\n",
        "            blob = TextBlob(text)\n",
        "            polarity = blob.sentiment.polarity\n",
        "\n",
        "            if polarity > 0.2:\n",
        "                return 'positive', abs(polarity)\n",
        "            elif polarity < -0.2:\n",
        "                return 'negative', abs(polarity)\n",
        "            else:\n",
        "                return 'neutral', 0.5\n",
        "        except:\n",
        "            return 'neutral', 0.5\n",
        "\n",
        "    def generate_one_comment(self):\n",
        "        \"\"\"Generate one natural comment\"\"\"\n",
        "\n",
        "        # Select place\n",
        "        place = np.random.choice(self.places)\n",
        "\n",
        "        # Select language (mix of French and English)\n",
        "        language = np.random.choice(['fr', 'en'], p=[0.6, 0.4])\n",
        "\n",
        "        # Select sentiment (mostly positive for tourism)\n",
        "        sentiments = ['positive', 'negative', 'neutral']\n",
        "        sentiment_probs = [0.65, 0.20, 0.15]\n",
        "        sentiment = np.random.choice(sentiments, p=sentiment_probs)\n",
        "\n",
        "        # Create prompt\n",
        "        prompt = self.create_simple_natural_prompt(place, sentiment, language)\n",
        "\n",
        "        # Generate text\n",
        "        text = self.generate_natural_text(prompt, language)\n",
        "\n",
        "        if not text:\n",
        "            self.stats['failed'] += 1\n",
        "            return None\n",
        "\n",
        "        # Analyze sentiment\n",
        "        predicted_sentiment, confidence = self.analyze_sentiment(text)\n",
        "\n",
        "        # Create comment data\n",
        "        comment_data = {\n",
        "            'id': f\"TUN_{self.stats['generated']:06d}\",\n",
        "            'text': text,\n",
        "            'language': language,\n",
        "            'place': place['name'],\n",
        "            'place_type': place['type'],\n",
        "            'target_sentiment': sentiment,\n",
        "            'predicted_sentiment': predicted_sentiment,\n",
        "            'sentiment_confidence': confidence,\n",
        "            'sentiment_match': sentiment == predicted_sentiment,\n",
        "            'rating': self._generate_rating(predicted_sentiment),\n",
        "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'word_count': len(text.split())\n",
        "        }\n",
        "\n",
        "        # Update stats\n",
        "        self.stats['generated'] += 1\n",
        "        self.stats[language] += 1\n",
        "\n",
        "        return comment_data\n",
        "\n",
        "    def _generate_rating(self, sentiment):\n",
        "        \"\"\"Generate realistic rating\"\"\"\n",
        "        if sentiment == 'positive':\n",
        "            return np.random.choice([4, 5])\n",
        "        elif sentiment == 'negative':\n",
        "            return np.random.choice([1, 2])\n",
        "        else:\n",
        "            return np.random.choice([3, 4])\n",
        "\n",
        "    def generate_dataset(self, num_comments=100, batch_size=20, save_frequency=20):\n",
        "        \"\"\"Generate dataset of natural comments\"\"\"\n",
        "\n",
        "        print(f\"\\nüöÄ Generating {num_comments:,} natural comments...\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        all_comments = []\n",
        "\n",
        "        # Generate\n",
        "        pbar = tqdm(total=num_comments, desc=\"Generating comments\")\n",
        "\n",
        "        while len(all_comments) < num_comments:\n",
        "            comment = self.generate_one_comment()\n",
        "\n",
        "            if comment:\n",
        "                all_comments.append(comment)\n",
        "                pbar.update(1)\n",
        "\n",
        "                # Show progress\n",
        "                if len(all_comments) % 10 == 0:\n",
        "                    print(f\"üìä Generated: {len(all_comments):,}/{num_comments:,}\")\n",
        "                    print(f\"   Success rate: {len(all_comments)/(len(all_comments)+self.stats['failed']):.1%}\")\n",
        "\n",
        "                # Save checkpoint\n",
        "                if len(all_comments) % save_frequency == 0:\n",
        "                    df_checkpoint = pd.DataFrame(all_comments)\n",
        "                    checkpoint_file = f\"tunisia_checkpoint_{len(all_comments)}.csv\"\n",
        "                    df_checkpoint.to_csv(checkpoint_file, index=False)\n",
        "                    print(f\"üíæ Checkpoint saved: {checkpoint_file}\")\n",
        "\n",
        "            # Break if too many failures\n",
        "            if self.stats['failed'] > 100 and len(all_comments) < 10:\n",
        "                print(\"‚ö†Ô∏è Too many failures, trying alternative approach...\")\n",
        "                # Reset and try again\n",
        "                break\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        if all_comments:\n",
        "            df = pd.DataFrame(all_comments)\n",
        "            print(f\"\\n‚úÖ Generation complete!\")\n",
        "            print(f\"   Generated: {len(df):,} comments\")\n",
        "            print(f\"   Failed: {self.stats['failed']:,}\")\n",
        "            print(f\"   Success rate: {len(df)/(len(df)+self.stats['failed']):.1%}\")\n",
        "            return df\n",
        "        else:\n",
        "            print(\"‚ùå No comments generated\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "# 3. TEST FUNCTION\n",
        "def test_generation():\n",
        "    \"\"\"Test the generator with small sample\"\"\"\n",
        "\n",
        "    print(\"üß™ Testing natural comment generation...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = WorkingTunisiaGenerator()\n",
        "\n",
        "    # Test 5 comments\n",
        "    test_comments = []\n",
        "\n",
        "    for i in range(5):\n",
        "        print(f\"\\nGenerating comment {i+1}/5...\")\n",
        "        comment = generator.generate_one_comment()\n",
        "\n",
        "        if comment:\n",
        "            test_comments.append(comment)\n",
        "            print(f\"‚úÖ Success! Language: {comment['language']}\")\n",
        "            print(f\"   Text: {comment['text'][:80]}...\")\n",
        "        else:\n",
        "            print(f\"‚ùå Failed\")\n",
        "\n",
        "    if test_comments:\n",
        "        df_test = pd.DataFrame(test_comments)\n",
        "        print(f\"\\nüéâ Test successful! Generated {len(test_comments)} comments.\")\n",
        "        return True, df_test\n",
        "    else:\n",
        "        print(\"\\n‚ùå Test failed\")\n",
        "        return False, None\n",
        "\n",
        "# 4. MAIN WORKING FUNCTION\n",
        "def main_working(num_comments=100):\n",
        "    \"\"\"Main working function\"\"\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üèùÔ∏è  WORKING TUNISIA NATURAL COMMENTS GENERATOR\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # First run a quick test\n",
        "    print(\"\\nüß™ Running quick test...\")\n",
        "    success, df_test = test_generation()\n",
        "\n",
        "    if not success:\n",
        "        print(\"\\n‚ùå Test failed. Cannot proceed with generation.\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\n‚úÖ Test passed! Starting main generation...\")\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = WorkingTunisiaGenerator()\n",
        "\n",
        "    # Generate dataset\n",
        "    df = generator.generate_dataset(num_comments=num_comments)\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(\"‚ùå No comments generated\")\n",
        "        return None\n",
        "\n",
        "    # Save results\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"tunisia_natural_comments_{len(df)}_{timestamp}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "    # Show statistics\n",
        "    print(f\"\\nüìä DATASET STATISTICS:\")\n",
        "    print(f\"   Total comments: {len(df):,}\")\n",
        "    print(f\"   French comments: {len(df[df['language'] == 'fr']):,}\")\n",
        "    print(f\"   English comments: {len(df[df['language'] == 'en']):,}\")\n",
        "    print(f\"   Sentiment distribution: {df['predicted_sentiment'].value_counts().to_dict()}\")\n",
        "    print(f\"   Average word count: {df['word_count'].mean():.1f}\")\n",
        "\n",
        "    # Show samples\n",
        "    print(f\"\\nüìù SAMPLE COMMENTS:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    samples = df.sample(min(3, len(df)))\n",
        "    for idx, row in samples.iterrows():\n",
        "        lang_flag = \"üá´üá∑\" if row['language'] == 'fr' else \"üá¨üáß\"\n",
        "        sentiment_icon = \"üòä\" if row['predicted_sentiment'] == 'positive' else \"üòû\" if row['predicted_sentiment'] == 'negative' else \"üòê\"\n",
        "\n",
        "        print(f\"\\n{lang_flag} {sentiment_icon} {row['place']}\")\n",
        "        print(f\"Rating: {row['rating']}/5 | Words: {row['word_count']}\")\n",
        "        print(f\"\\\"{row['text']}\\\"\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    print(f\"\\nüíæ Saved to: {filename}\")\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "DYiE768DFjQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. GOOGLE COLAB EXECUTION\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"\\nüéõÔ∏è  WORKING TUNISIA COMMENTS GENERATOR - GOOGLE COLAB\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"1. Quick test (5 comments)\")\n",
        "    print(\"2. Small dataset (100 comments)\")\n",
        "    print(\"3. Medium dataset (500 comments)\")\n",
        "    print(\"4. Large dataset (2,000 comments)\")\n",
        "    print(\"5. Full dataset (10,000 comments)\")\n",
        "\n",
        "    choice = input(\"\\nEnter choice (1-5): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        print(\"\\nüß™ Running quick test...\")\n",
        "        success, df_test = test_generation()\n",
        "        if success and df_test is not None:\n",
        "            df_test.to_csv(\"tunisia_test_5_comments.csv\", index=False)\n",
        "            print(\"\\n‚úÖ Test complete! Saved to tunisia_test_5_comments.csv\")\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        print(\"\\nüöÄ Generating 100 natural comments...\")\n",
        "        df = main_working(100)\n",
        "        if df is not None:\n",
        "            print(\"\\n‚úÖ Complete! Ready for download.\")\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        print(\"\\nüöÄ Generating 500 natural comments...\")\n",
        "        df = main_working(500)\n",
        "        if df is not None:\n",
        "            print(\"\\n‚úÖ Complete! Ready for download.\")\n",
        "\n",
        "    elif choice == \"4\":\n",
        "        print(\"\\nüöÄ Generating 2,000 natural comments...\")\n",
        "        df = main_working(2000)\n",
        "        if df is not None:\n",
        "            print(\"\\n‚úÖ Complete! Ready for download.\")\n",
        "\n",
        "    elif choice == \"5\":\n",
        "        print(\"\\n‚ö†Ô∏è  Generating 10,000 comments (this will take 1-2 hours)\")\n",
        "        confirm = input(\"Continue? (yes/no): \").strip().lower()\n",
        "        if confirm in ['yes', 'y']:\n",
        "            df = main_working(10000)\n",
        "            if df is not None:\n",
        "                print(\"\\n‚úÖ Complete! Ready for download.\")\n",
        "        else:\n",
        "            print(\"‚ùå Operation cancelled.\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice\")\n",
        "\n",
        "    print(\"\\n‚ú® Script execution completed!\")"
      ],
      "metadata": {
        "id": "VtC_UGP5jPCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}